{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1f112ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import datetime as datetime\n",
    "from nba_api.stats.endpoints import (\n",
    "    boxscoreadvancedv3,\n",
    "    leaguegamefinder,\n",
    "    boxscoretraditionalv3)\n",
    "from nba_api.stats.static import teams\n",
    "import requests\n",
    "from requests.exceptions import Timeout, ConnectionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb51e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2025-26 NBA Schedule...\n",
      "Processed February...\n",
      "Processed March...\n",
      "Processed April...\n",
      "Success! Saved 501 games to nba_schedule_2025-2026.csv\n"
     ]
    }
   ],
   "source": [
    "#Scraping future games for the 2025-26 season\n",
    "\n",
    "# List of months remaining in the 2025-26 season\n",
    "months = ['february', 'march', 'april']\n",
    "season_year = 2026\n",
    "all_games = []\n",
    "\n",
    "print(\"Fetching 2025-26 NBA Schedule...\")\n",
    "\n",
    "for month in months:\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season_year}_games-{month}.html\"\n",
    "    try:\n",
    "        # Read the tables from the page\n",
    "        tables = pd.read_html(url)\n",
    "        # The first table is usually the schedule\n",
    "        df = tables[0]\n",
    "        \n",
    "        # Rename columns for clarity (Standardizing Headers)\n",
    "        df.rename(columns={\n",
    "            'Date': 'Date',\n",
    "            'Start (ET)': 'Time (ET)',\n",
    "            'Visitor/Neutral': 'Away Team',\n",
    "            'Home/Neutral': 'Home Team',\n",
    "            'Arena': 'Venue'\n",
    "        }, inplace=True)\n",
    "        \n",
    "        # Keep only relevant columns\n",
    "        cols_to_keep = ['Date', 'Time (ET)', 'Away Team', 'Home Team', 'Venue']\n",
    "        # Check if columns exist before selecting\n",
    "        df = df[[c for c in cols_to_keep if c in df.columns]]\n",
    "        \n",
    "        # Filter out \"Playoffs\" headers or empty rows if any exist in the raw data\n",
    "        df = df[df['Date'] != 'Date']\n",
    "        \n",
    "        all_games.append(df)\n",
    "        print(f\"Processed {month.capitalize()}...\")\n",
    "        time.sleep(2) # Be polite to the server\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Could not retrieve data for {month}: {e}\")\n",
    "\n",
    "# Combine all months\n",
    "full_schedule = pd.concat(all_games, ignore_index=True)\n",
    "\n",
    "# Filter for future games only (From Jan 27, 2026 onwards)\n",
    "# Convert date column to datetime objects\n",
    "full_schedule['Date_Obj'] = pd.to_datetime(full_schedule['Date'])\n",
    "cutoff_date = pd.Timestamp(\"2026-01-27\")\n",
    "future_games = full_schedule[full_schedule['Date_Obj'] >= cutoff_date].copy()\n",
    "\n",
    "# Sort by date\n",
    "future_games.sort_values(by='Date_Obj', inplace=True)\n",
    "\n",
    "# Drop helper column\n",
    "future_games.drop(columns=['Date_Obj'], inplace=True)\n",
    "\n",
    "# Save to CSV\n",
    "filename = 'nba_schedule_2025-2026.csv'\n",
    "future_games.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Success! Saved {len(future_games)} games to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51b2d45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NBA Season Scraper - 2025-26\n",
      "============================================================\n",
      "Output: 2025-26 season\n",
      "Fetching TEAM-LEVEL stats with OPPONENT names\n",
      "Delay: 1.0s | Timeout: 60s | Retries: 3\n",
      "Saves every 5 games with deduplication\n",
      "\n",
      "Processing all 30 teams\n",
      "\n",
      "============================================================\n",
      "[1/30] Atlanta Hawks\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Atlanta Hawks (ID: 1610612737)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Atlanta_Hawks_2025-26.csv\n",
      "   Already have 54 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612737\n",
      "Fetching playoff games for team ID: 1610612737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500765     Removed 1 duplicate games\n",
      "SAVED (56 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 56 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[2/30] Boston Celtics\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Boston Celtics (ID: 1610612738)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Boston_Celtics_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612738\n",
      "Fetching playoff games for team ID: 1610612738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 total games for the season\n",
      "All games already collected for Boston Celtics\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[3/30] Cleveland Cavaliers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Cleveland Cavaliers (ID: 1610612739)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Cleveland_Cavaliers_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612739\n",
      "Fetching playoff games for team ID: 1610612739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500767     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[4/30] New Orleans Pelicans\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping New Orleans Pelicans (ID: 1610612740)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/New_Orleans_Pelicans_2025-26.csv\n",
      "   Already have 54 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612740\n",
      "Fetching playoff games for team ID: 1610612740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500766     Removed 1 duplicate games\n",
      "SAVED (56 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 56 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[5/30] Chicago Bulls\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Chicago Bulls (ID: 1610612741)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Chicago_Bulls_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612741\n",
      "Fetching playoff games for team ID: 1610612741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500762     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[6/30] Dallas Mavericks\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Dallas Mavericks (ID: 1610612742)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Dallas_Mavericks_2025-26.csv\n",
      "   Already have 52 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612742\n",
      "Fetching playoff games for team ID: 1610612742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "All games already collected for Dallas Mavericks\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[7/30] Denver Nuggets\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Denver Nuggets (ID: 1610612743)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Denver_Nuggets_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612743\n",
      "Fetching playoff games for team ID: 1610612743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500767     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[8/30] Golden State Warriors\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Golden State Warriors (ID: 1610612744)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Golden_State_Warriors_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612744\n",
      "Fetching playoff games for team ID: 1610612744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500768     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[9/30] Houston Rockets\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Houston Rockets (ID: 1610612745)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Houston_Rockets_2025-26.csv\n",
      "   Already have 51 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612745\n",
      "Fetching playoff games for team ID: 1610612745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 total games for the season\n",
      "All games already collected for Houston Rockets\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[10/30] Los Angeles Clippers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Los Angeles Clippers (ID: 1610612746)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Los_Angeles_Clippers_2025-26.csv\n",
      "   Already have 52 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612746\n",
      "Fetching playoff games for team ID: 1610612746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "All games already collected for Los Angeles Clippers\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[11/30] Los Angeles Lakers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Los Angeles Lakers (ID: 1610612747)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Los_Angeles_Lakers_2025-26.csv\n",
      "   Already have 51 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612747\n",
      "Fetching playoff games for team ID: 1610612747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500769     Removed 1 duplicate games\n",
      "SAVED (53 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 53 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[12/30] Miami Heat\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Miami Heat (ID: 1610612748)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Miami_Heat_2025-26.csv\n",
      "   Already have 54 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612748\n",
      "Fetching playoff games for team ID: 1610612748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500763     Removed 1 duplicate games\n",
      "SAVED (56 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 56 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[13/30] Milwaukee Bucks\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Milwaukee Bucks (ID: 1610612749)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Milwaukee_Bucks_2025-26.csv\n",
      "   Already have 50 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612749\n",
      "Fetching playoff games for team ID: 1610612749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500764     Removed 1 duplicate games\n",
      "SAVED (52 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 52 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[14/30] Minnesota Timberwolves\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Minnesota Timberwolves (ID: 1610612750)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Minnesota_Timberwolves_2025-26.csv\n",
      "   Already have 54 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612750\n",
      "Fetching playoff games for team ID: 1610612750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500765     Removed 1 duplicate games\n",
      "SAVED (56 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 56 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[15/30] Brooklyn Nets\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Brooklyn Nets (ID: 1610612751)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Brooklyn_Nets_2025-26.csv\n",
      "   Already have 51 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612751\n",
      "Fetching playoff games for team ID: 1610612751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500762     Removed 1 duplicate games\n",
      "SAVED (53 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 53 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[16/30] New York Knicks\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping New York Knicks (ID: 1610612752)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/New_York_Knicks_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612752\n",
      "Fetching playoff games for team ID: 1610612752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 total games for the season\n",
      "All games already collected for New York Knicks\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[17/30] Orlando Magic\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Orlando Magic (ID: 1610612753)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Orlando_Magic_2025-26.csv\n",
      "   Already have 51 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612753\n",
      "Fetching playoff games for team ID: 1610612753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500764     Removed 1 duplicate games\n",
      "SAVED (53 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 53 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[18/30] Indiana Pacers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Indiana Pacers (ID: 1610612754)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Indiana_Pacers_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612754\n",
      "Fetching playoff games for team ID: 1610612754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 total games for the season\n",
      "All games already collected for Indiana Pacers\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[19/30] Philadelphia 76ers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Philadelphia 76ers (ID: 1610612755)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Philadelphia_76ers_2025-26.csv\n",
      "   Already have 52 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612755\n",
      "Fetching playoff games for team ID: 1610612755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500770     Removed 1 duplicate games\n",
      "SAVED (54 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 54 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[20/30] Phoenix Suns\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Phoenix Suns (ID: 1610612756)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Phoenix_Suns_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612756\n",
      "Fetching playoff games for team ID: 1610612756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 total games for the season\n",
      "All games already collected for Phoenix Suns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[21/30] Portland Trail Blazers\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Portland Trail Blazers (ID: 1610612757)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Portland_Trail_Blazers_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612757\n",
      "Fetching playoff games for team ID: 1610612757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500770     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[22/30] Sacramento Kings\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Sacramento Kings (ID: 1610612758)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Sacramento_Kings_2025-26.csv\n",
      "   Already have 54 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612758\n",
      "Fetching playoff games for team ID: 1610612758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 55 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500766     Removed 1 duplicate games\n",
      "SAVED (56 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 56 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[23/30] San Antonio Spurs\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping San Antonio Spurs (ID: 1610612759)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/San_Antonio_Spurs_2025-26.csv\n",
      "   Already have 52 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612759\n",
      "Fetching playoff games for team ID: 1610612759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "All games already collected for San Antonio Spurs\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[24/30] Oklahoma City Thunder\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Oklahoma City Thunder (ID: 1610612760)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Oklahoma_City_Thunder_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612760\n",
      "Fetching playoff games for team ID: 1610612760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500769     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[25/30] Toronto Raptors\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Toronto Raptors (ID: 1610612761)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Toronto_Raptors_2025-26.csv\n",
      "   Already have 54 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612761\n",
      "Fetching playoff games for team ID: 1610612761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "All games already collected for Toronto Raptors\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[26/30] Utah Jazz\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Utah Jazz (ID: 1610612762)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Utah_Jazz_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612762\n",
      "Fetching playoff games for team ID: 1610612762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500763     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[27/30] Memphis Grizzlies\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Memphis Grizzlies (ID: 1610612763)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Memphis_Grizzlies_2025-26.csv\n",
      "   Already have 51 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612763\n",
      "Fetching playoff games for team ID: 1610612763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500768     Removed 1 duplicate games\n",
      "SAVED (53 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 53 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[28/30] Washington Wizards\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Washington Wizards (ID: 1610612764)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Washington_Wizards_2025-26.csv\n",
      "   Already have 52 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612764\n",
      "Fetching playoff games for team ID: 1610612764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "All games already collected for Washington Wizards\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[29/30] Detroit Pistons\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Detroit Pistons (ID: 1610612765)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Detroit_Pistons_2025-26.csv\n",
      "   Already have 51 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612765\n",
      "Fetching playoff games for team ID: 1610612765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500761     Removed 1 duplicate games\n",
      "SAVED (53 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 53 total games | 78 columns\n",
      "Waiting 2s before next team...\n",
      "\n",
      "============================================================\n",
      "[30/30] Charlotte Hornets\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Scraping Charlotte Hornets (ID: 1610612766)\n",
      "============================================================\n",
      "Found existing file: 2025-26 season/Charlotte_Hornets_2025-26.csv\n",
      "   Already have 53 games. Will fetch missing games only.\n",
      "Fetching game list for team ID: 1610612766\n",
      "Fetching playoff games for team ID: 1610612766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeong\\AppData\\Local\\Temp\\ipykernel_9104\\2647262656.py:205: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 total games for the season\n",
      "Need to fetch 1 new games\n",
      "[1/1] Game 0022500761     Removed 1 duplicate games\n",
      "SAVED (55 total)\n",
      "    Removed 1 duplicate games\n",
      "\n",
      "Complete: 55 total games | 78 columns\n",
      "\n",
      "============================================================\n",
      "COMPLETE! Files in: 2025-26 season\n",
      "============================================================\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class NBASeasonScraper:\n",
    "    def __init__(self, season='2025-26'):\n",
    "        self.season = season\n",
    "        self.output_dir = f'{season.replace(\"-\", \"-\")} season'\n",
    "        self.teams = teams.get_teams()\n",
    "        self.delay = 1.0\n",
    "        self.max_retries = 3\n",
    "        self.timeout = 60\n",
    "        \n",
    "        # Create team ID to name mapping\n",
    "        self.team_id_to_name = {team['id']: team['full_name'] for team in self.teams}\n",
    "        \n",
    "    def create_output_directory(self):\n",
    "        \"\"\"Create directory for storing CSV files\"\"\"\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "            print(f\"Created directory: {self.output_dir}\")\n",
    "    \n",
    "    def retry_api_call(self, api_func, *args, **kwargs):\n",
    "        \"\"\"Retry an API call with exponential backoff\"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                time.sleep(self.delay)\n",
    "                result = api_func(*args, **kwargs)\n",
    "                return result\n",
    "            except (Timeout, ConnectionError) as e:\n",
    "                wait_time = self.delay * (2 ** attempt)\n",
    "                print(f\"    Timeout (attempt {attempt + 1}/{self.max_retries}). Waiting {wait_time:.1f}s...\")\n",
    "                time.sleep(wait_time)\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    print(f\"    Failed after {self.max_retries} attempts: {e}\")\n",
    "                    return None\n",
    "            except Exception as e:\n",
    "                print(f\"    Error: {e}\")\n",
    "                return None\n",
    "        return None\n",
    "        \n",
    "    def get_team_games(self, team_id):\n",
    "        \"\"\"Fetch all games for a specific team in the season\"\"\"\n",
    "        print(f\"Fetching game list for team ID: {team_id}\")\n",
    "        \n",
    "        def fetch():\n",
    "            gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "                team_id_nullable=team_id,\n",
    "                season_nullable=self.season,\n",
    "                season_type_nullable='Regular Season',\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            return gamefinder.get_data_frames()[0]\n",
    "        \n",
    "        result = self.retry_api_call(fetch)\n",
    "        return result if result is not None else pd.DataFrame()\n",
    "    \n",
    "    def get_playoff_games(self, team_id):\n",
    "        \"\"\"Fetch playoff games for a specific team\"\"\"\n",
    "        print(f\"Fetching playoff games for team ID: {team_id}\")\n",
    "        \n",
    "        def fetch():\n",
    "            gamefinder = leaguegamefinder.LeagueGameFinder(\n",
    "                team_id_nullable=team_id,\n",
    "                season_nullable=self.season,\n",
    "                season_type_nullable='Playoffs',\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            return gamefinder.get_data_frames()[0]\n",
    "        \n",
    "        result = self.retry_api_call(fetch)\n",
    "        return result if result is not None else pd.DataFrame()\n",
    "    \n",
    "    def get_team_box_score_traditional(self, game_id):\n",
    "        \"\"\"\n",
    "        Fetch traditional team box score for a game\n",
    "        Returns: DataFrame with TEAM-LEVEL stats (not player stats)\n",
    "        \"\"\"\n",
    "        def fetch():\n",
    "            traditional = boxscoretraditionalv3.BoxScoreTraditionalV3(\n",
    "                game_id=game_id,\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            # Index 1 = Team stats (Index 0 = Player stats)\n",
    "            return traditional.get_data_frames()[1]\n",
    "        \n",
    "        result = self.retry_api_call(fetch)\n",
    "        return result if result is not None else pd.DataFrame()\n",
    "    \n",
    "    def get_team_box_score_advanced(self, game_id):\n",
    "        \"\"\"\n",
    "        Fetch advanced team box score for a game\n",
    "        Returns: DataFrame with TEAM-LEVEL advanced stats\n",
    "        \"\"\"\n",
    "        def fetch():\n",
    "            advanced = boxscoreadvancedv3.BoxScoreAdvancedV3(\n",
    "                game_id=game_id,\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            # Index 1 = Team stats (Index 0 = Player stats)\n",
    "            return advanced.get_data_frames()[1]\n",
    "        \n",
    "        result = self.retry_api_call(fetch)\n",
    "        return result if result is not None else pd.DataFrame()\n",
    "    \n",
    "    def get_team_game_data(self, game_id, team_id):\n",
    "        \"\"\"\n",
    "        Merge traditional and advanced TEAM box score data for a single game\n",
    "        Only returns data for the specified team (not opponent)\n",
    "        Also adds opponent team name\n",
    "        \"\"\"\n",
    "        # Fetch TEAM box scores (not player box scores)\n",
    "        traditional = self.get_team_box_score_traditional(game_id)\n",
    "        advanced = self.get_team_box_score_advanced(game_id)\n",
    "        \n",
    "        # Get opponent name\n",
    "        opponent_name = \"Unknown\"\n",
    "        if traditional is not None and not traditional.empty and 'teamId' in traditional.columns:\n",
    "            team_ids = traditional['teamId'].tolist()\n",
    "            for tid in team_ids:\n",
    "                if tid != team_id:\n",
    "                    opponent_name = self.team_id_to_name.get(tid, f\"Team_{tid}\")\n",
    "                    break\n",
    "        \n",
    "        # Filter for specific team and merge\n",
    "        dataframes = []\n",
    "        \n",
    "        if traditional is not None and not traditional.empty:\n",
    "            if 'teamId' in traditional.columns:\n",
    "                team_df = traditional[traditional['teamId'] == team_id].copy()\n",
    "                if not team_df.empty:\n",
    "                    dataframes.append(team_df)\n",
    "        \n",
    "        if advanced is not None and not advanced.empty:\n",
    "            if 'teamId' in advanced.columns:\n",
    "                team_df = advanced[advanced['teamId'] == team_id].copy()\n",
    "                if not team_df.empty:\n",
    "                    dataframes.append(team_df)\n",
    "        \n",
    "        # Merge dataframes\n",
    "        if len(dataframes) == 2:\n",
    "            merged = pd.merge(\n",
    "                dataframes[0], \n",
    "                dataframes[1], \n",
    "                on=['gameId', 'teamId'], \n",
    "                how='outer',\n",
    "                suffixes=('', '_adv')\n",
    "            )\n",
    "            # Remove duplicate columns\n",
    "            merged = merged.loc[:, ~merged.columns.str.endswith('_adv')]\n",
    "            # Add opponent name as first column\n",
    "            merged.insert(0, 'OPPONENT', opponent_name)\n",
    "            return merged\n",
    "        elif len(dataframes) == 1:\n",
    "            result = dataframes[0]\n",
    "            # Add opponent name as first column\n",
    "            result.insert(0, 'OPPONENT', opponent_name)\n",
    "            return result\n",
    "        \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    def save_team_data(self, team_name, team_season_df):\n",
    "        \"\"\"Save team data to CSV file\"\"\"\n",
    "        filename = f\"{self.output_dir}/{team_name.replace(' ', '_')}_2025-26.csv\"\n",
    "        \n",
    "        # Remove duplicates based on GAME_ID before saving\n",
    "        if 'GAME_ID' in team_season_df.columns:\n",
    "            original_count = len(team_season_df)\n",
    "            team_season_df = team_season_df.drop_duplicates(subset=['GAME_ID'], keep='first')\n",
    "            deduped_count = len(team_season_df)\n",
    "            if original_count != deduped_count:\n",
    "                print(f\"    Removed {original_count - deduped_count} duplicate games\")\n",
    "        \n",
    "        # Sort by game date if available\n",
    "        if 'GAME_DATE' in team_season_df.columns:\n",
    "            team_season_df = team_season_df.sort_values('GAME_DATE')\n",
    "        \n",
    "        # Save to CSV\n",
    "        team_season_df.to_csv(filename, index=False)\n",
    "        return filename\n",
    "    \n",
    "    def scrape_team_season(self, team_id, team_name):\n",
    "        \"\"\"Scrape entire season for a single team, saving incrementally\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Scraping {team_name} (ID: {team_id})\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # Define the filename for this team\n",
    "        filename = f\"{self.output_dir}/{team_name.replace(' ', '_')}_2025-26.csv\"\n",
    "        \n",
    "        # Check if file already exists and load it\n",
    "        if os.path.exists(filename):\n",
    "            print(f\"Found existing file: {filename}\")\n",
    "            # --- FIX: Added dtype={'GAME_ID': str} to prevent stripping leading zeros ---\n",
    "            existing_df = pd.read_csv(filename, dtype={'GAME_ID': str})\n",
    "            # Remove any duplicates from existing file\n",
    "            if 'GAME_ID' in existing_df.columns:\n",
    "                existing_df = existing_df.drop_duplicates(subset=['GAME_ID'], keep='first')\n",
    "            existing_game_ids = set(existing_df['GAME_ID'].values) if 'GAME_ID' in existing_df.columns else set()\n",
    "            print(f\"   Already have {len(existing_game_ids)} games. Will fetch missing games only.\")\n",
    "        else:\n",
    "            existing_df = pd.DataFrame()\n",
    "            existing_game_ids = set()\n",
    "        \n",
    "        # Get regular season games\n",
    "        regular_games = self.get_team_games(team_id)\n",
    "        playoff_games = self.get_playoff_games(team_id)\n",
    "        \n",
    "        all_games = pd.concat([regular_games, playoff_games], ignore_index=True)\n",
    "        \n",
    "        if all_games.empty:\n",
    "            print(f\"No games found for {team_name}\")\n",
    "            return\n",
    "        \n",
    "        # Remove duplicates from API response\n",
    "        if 'GAME_ID' in all_games.columns:\n",
    "            original_count = len(all_games)\n",
    "            all_games = all_games.drop_duplicates(subset=['GAME_ID'], keep='first')\n",
    "            if original_count != len(all_games):\n",
    "                print(f\"Removed {original_count - len(all_games)} duplicate game entries from API\")\n",
    "        \n",
    "        print(f\"Found {len(all_games)} total games for the season\")\n",
    "        \n",
    "        # Get unique game IDs\n",
    "        all_game_ids = set(all_games['GAME_ID'].unique())\n",
    "        \n",
    "        # Determine which games need to be fetched\n",
    "        games_to_fetch = all_game_ids - existing_game_ids\n",
    "        \n",
    "        if not games_to_fetch:\n",
    "            print(f\"All games already collected for {team_name}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Need to fetch {len(games_to_fetch)} new games\")\n",
    "        \n",
    "        # Collect detailed stats for each new game\n",
    "        new_games_list = []\n",
    "        failed_games = []\n",
    "        games_fetched = sorted(games_to_fetch)\n",
    "        \n",
    "        for idx, game_id in enumerate(games_fetched, 1):\n",
    "            print(f\"[{idx}/{len(games_fetched)}] Game {game_id}\", end=\" \")\n",
    "            \n",
    "            # Get basic game info from leaguegamefinder\n",
    "            game_info = all_games[all_games['GAME_ID'] == game_id].iloc[0].to_dict()\n",
    "            \n",
    "            # Get detailed TEAM box scores (includes opponent name)\n",
    "            detailed_stats = self.get_team_game_data(game_id, team_id)\n",
    "            \n",
    "            if not detailed_stats.empty:\n",
    "                # Combine basic info with detailed stats\n",
    "                for key, value in game_info.items():\n",
    "                    if key not in detailed_stats.columns:\n",
    "                        detailed_stats[key] = value\n",
    "                \n",
    "                new_games_list.append(detailed_stats)\n",
    "                \n",
    "                # SAVE EVERY 5 GAMES\n",
    "                if idx % 5 == 0 or idx == len(games_fetched):\n",
    "                    if not existing_df.empty:\n",
    "                        updated_df = pd.concat([existing_df] + new_games_list, ignore_index=True)\n",
    "                    else:\n",
    "                        updated_df = pd.concat(new_games_list, ignore_index=True)\n",
    "                    \n",
    "                    self.save_team_data(team_name, updated_df)\n",
    "                    print(f\"SAVED ({len(updated_df)} total)\")\n",
    "                else:\n",
    "                    print(f\"OK\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"FAILED\")\n",
    "                failed_games.append(game_id)\n",
    "        \n",
    "        # Final save with all games\n",
    "        if new_games_list:\n",
    "            if not existing_df.empty:\n",
    "                final_df = pd.concat([existing_df] + new_games_list, ignore_index=True)\n",
    "            else:\n",
    "                final_df = pd.concat(new_games_list, ignore_index=True)\n",
    "            \n",
    "            saved_file = self.save_team_data(team_name, final_df)\n",
    "            print(f\"\\nComplete: {len(final_df)} total games | {len(final_df.columns)} columns\")\n",
    "            \n",
    "            if failed_games:\n",
    "                print(f\"Failed: {len(failed_games)} games - {failed_games[:3]}...\")\n",
    "        elif not existing_df.empty:\n",
    "            print(f\"No new games added\")\n",
    "        else:\n",
    "            print(f\"No data collected\")\n",
    "    \n",
    "    def scrape_all_teams(self, start_from_team=None, teams_list=None):\n",
    "        \"\"\"\n",
    "        Scrape data for NBA teams\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        start_from_team : str, optional\n",
    "            Team name to start from\n",
    "        teams_list : list, optional\n",
    "            List of specific team names to scrape\n",
    "        \"\"\"\n",
    "        self.create_output_directory()\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"NBA Season Scraper - {self.season}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Output: {self.output_dir}\")\n",
    "        print(f\"Fetching TEAM-LEVEL stats with OPPONENT names\")\n",
    "        print(f\"Delay: {self.delay}s | Timeout: {self.timeout}s | Retries: {self.max_retries}\")\n",
    "        print(f\"Saves every 5 games with deduplication\\n\")\n",
    "        \n",
    "        # Determine which teams to process\n",
    "        if teams_list:\n",
    "            teams_to_process = [t for t in self.teams if t['full_name'] in teams_list]\n",
    "            print(f\"Processing {len(teams_to_process)} specific teams\")\n",
    "        else:\n",
    "            teams_to_process = self.teams\n",
    "            print(f\"Processing all {len(teams_to_process)} teams\")\n",
    "        \n",
    "        start_idx = 0\n",
    "        if start_from_team and not teams_list:\n",
    "            for idx, team in enumerate(teams_to_process):\n",
    "                if team['full_name'].lower() == start_from_team.lower():\n",
    "                    start_idx = idx\n",
    "                    print(f\"Starting from: {team['full_name']}\\n\")\n",
    "                    break\n",
    "        \n",
    "        for idx, team in enumerate(teams_to_process[start_idx:], start_idx + 1):\n",
    "            team_id = team['id']\n",
    "            team_name = team['full_name']\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"[{idx}/{len(teams_to_process)}] {team_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            try:\n",
    "                self.scrape_team_season(team_id, team_name)\n",
    "            except KeyboardInterrupt:\n",
    "                print(f\"\\n\\nInterrupted!\")\n",
    "                print(f\"Last team: {team_name}\")\n",
    "                print(f\"Resume: scraper.scrape_all_teams(start_from_team='{team_name}')\")\n",
    "                raise\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "            \n",
    "            # Delay between teams\n",
    "            if idx < len(teams_to_process):\n",
    "                print(f\"Waiting 2s before next team...\")\n",
    "                time.sleep(2)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"COMPLETE! Files in: {self.output_dir}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    scraper = NBASeasonScraper(season='2025-26')\n",
    "    \n",
    "    # Option 1: Scrape all teams\n",
    "    scraper.scrape_all_teams()\n",
    "    \n",
    "    # Option 2: Scrape specific teams only\n",
    "    # scraper.scrape_all_teams(teams_list=['Los Angeles Lakers', 'Boston Celtics'])\n",
    "    \n",
    "    # Option 3: Resume from a specific team\n",
    "    # scraper.scrape_all_teams(start_from_team='Chicago Bulls')\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacb455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}